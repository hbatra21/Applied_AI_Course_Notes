{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Amazon Fine Food Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd #for data frames\n",
    "import numpy as np #numpy array operations\n",
    "import nltk #natural lang processing, for processing text\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #for plotting\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score,f1_score,precision_score,recall_score,auc,log_loss,confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.stats import expon\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in=open(\"cleanedData.pickle\",\"rb\")\n",
    "final = pickle.load(pickle_in)\n",
    "\n",
    "'''pickle_in = open(\"BOW_tfidf_avgW2V_TfidfW2V.pickle\",\"rb\")\n",
    "count_vect = pickle.load(pickle_in) #BOW\n",
    "final_counts = pickle.load(pickle_in) #BOW\n",
    "\n",
    "tf_idf_vect = pickle.load(pickle_in) #TFIDF\n",
    "final_tf_idf = pickle.load(pickle_in) #TFIDF\n",
    "features = pickle.load(pickle_in) #TFIDF\n",
    "\n",
    "w2v_model = pickle.load(pickle_in) #w2v\n",
    "words = pickle.load(pickle_in) #w2v\n",
    "\n",
    "sent_vectors = pickle.load(pickle_in) #avg W2V'''\n",
    "\n",
    "import pickle\n",
    "pickle_in = open(\"BOW_tfidf_avgW2V_Train_test_data.pickle\",\"rb\")\n",
    "\n",
    "count_vect = pickle.load(pickle_in) #BOW\n",
    "final_counts_train = pickle.load(pickle_in) #BOW\n",
    "final_counts_test = pickle.load(pickle_in) #BOW\n",
    "tf_idf_vect = pickle.load(pickle_in) #tfidf\n",
    "final_tf_idf_train = pickle.load(pickle_in) #tfidf\n",
    "final_tf_idf_test = pickle.load(pickle_in) #tfidf\n",
    "features = pickle.load(pickle_in) \n",
    "sent_vectors_train = pickle.load(pickle_in) #avgW2v Vectors\n",
    "sent_vectors_test = pickle.load(pickle_in) #avgW2v Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291336"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = final.head(int(0.80*final.shape[0]))\n",
    "test_data = final.head(int(0.20*final.shape[0])+1)\n",
    "\n",
    "scores = final['Score'].get_values()\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convScores(scores):\n",
    "    li = lambda x: 1 if x=='positive'  else 0\n",
    "    final_scores = []\n",
    "    for i in range(0,len(scores)):\n",
    "        final_scores.append(li(scores[i]))\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convToNpArray(arr):\n",
    "    if(type(arr) == list):\n",
    "        arr = np.array(arr)\n",
    "        return arr\n",
    "    else:\n",
    "        return arr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y_test,pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    tpr = tp/(fn+tp)\n",
    "    tnr = tn/(tn+fp)\n",
    "    fnr = fn/(fn+tp)\n",
    "    fpr = fp/(tn+fp)\n",
    "    \n",
    "    print(\"\\n######### Confusion Matrix #########\")\n",
    "    print(\"TPR :%f \\t TNR : %f\\nFPR : %f \\t FNR: %f\"%(tpr,tnr,fpr,fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data frame\n",
    "\n",
    "x_1 = final_counts_train[0:10000]\n",
    "\n",
    "\n",
    "# this is only Score/rating  of data\n",
    "\n",
    "y_1 = convScores(train_data['Score'].get_values())[0:10000]\n",
    "\n",
    "x_test = final_counts_test[0:3000]\n",
    "y_test = convScores(test_data['Score'].get_values())[0:3000]\n",
    "\n",
    "#x_1, x_test, y_1, y_test = train_test_split(x,y, test_size=0.3, random_state=0)\n",
    "\n",
    "x_1 = convToNpArray(x_1)\n",
    "x_test = convToNpArray(x_test)\n",
    "y_1 = convToNpArray(y_1)\n",
    "y_test = convToNpArray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score:  0.9973674313651749\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'C':[10**-2,10**0,10,10**2,10**4],\n",
    "                    'gamma':[0.0001,0.001,0.01,0.1,1]}\n",
    "\n",
    "\n",
    "svc_model = SVC(kernel='rbf',class_weight='balanced')\n",
    "model = GridSearchCV(svc_model,tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.994749 \t TNR : 1.000000\n",
      "FPR : 0.000000 \t FNR: 0.005251\n"
     ]
    }
   ],
   "source": [
    "best_svc_model = model.best_estimator_\n",
    "best_svc_model.fit(x_1,y_1)\n",
    "pred = best_svc_model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.6677202991576625, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.15473857217161935,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "import random\n",
    "g_val=[]\n",
    "for i in range(10):\n",
    "    g_val.append(random.random())\n",
    "tuned_parameters = {'C':expon(scale=10),'gamma':g_val}\n",
    "\n",
    "model = RandomizedSearchCV(SVC(kernel='rbf',class_weight='balanced'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :1.000000 \t TNR : 1.000000\n",
      "FPR : 0.000000 \t FNR: 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc_Model = model.best_estimator_\n",
    "svc_Model.fit(x_1,y_1)\n",
    "pred = svc_Model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: here it took gamma as large val, we can see that its Overfit case as TPR is 1, from this we can uderstand that if gamma increases model will be overfitted and will not give appropriate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avg W2v SVC  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = sent_vectors_train[0:10000]\n",
    "\n",
    "\n",
    "# this is only Score/rating  of data\n",
    "\n",
    "y_1 = convScores(train_data['Score'].get_values())[0:10000]\n",
    "\n",
    "x_test = sent_vectors_test[0:3000]\n",
    "y_test = convScores(test_data['Score'].get_values())[0:3000]\n",
    "\n",
    "\n",
    "x_1 = convToNpArray(x_1)\n",
    "x_test = convToNpArray(x_test)\n",
    "y_1 = convToNpArray(y_1)\n",
    "y_test = convToNpArray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score:  0.9299709724238027\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'C':[1,10,10**2,10**4],\n",
    "                    'gamma':[0.1,0.3,0.5,0.7]}\n",
    "\n",
    "\n",
    "svc_model = SVC(kernel='rbf',class_weight='balanced')\n",
    "model = GridSearchCV(svc_model,tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.961365 \t TNR : 0.152695\n",
      "FPR : 0.847305 \t FNR: 0.038635\n"
     ]
    }
   ],
   "source": [
    "best_svc_model = model.best_estimator_\n",
    "best_svc_model.fit(x_1,y_1)\n",
    "pred = best_svc_model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=13.121730339609785, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.14483763756915313,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "Score:  0.9385216773276475\n",
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.990623 \t TNR : 0.038922\n",
      "FPR : 0.961078 \t FNR: 0.009377\n"
     ]
    }
   ],
   "source": [
    "g_val=[]\n",
    "for i in range(10):\n",
    "    g_val.append(random.random())\n",
    "tuned_parameters = {'C':expon(scale=10),'gamma':g_val}\n",
    "\n",
    "\n",
    "model = RandomizedSearchCV(SVC(kernel='rbf',class_weight='balanced'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n",
    "best_svc_model = model.best_estimator_\n",
    "best_svc_model.fit(x_1,y_1)\n",
    "pred = best_svc_model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIDF SVC with GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = final_tf_idf_train[0:10000]\n",
    "\n",
    "y_1 = convScores(train_data['Score'].get_values())[0:10000]\n",
    "\n",
    "x_test = final_tf_idf_test[0:3000]\n",
    "y_test = convScores(test_data['Score'].get_values())[0:3000]\n",
    "\n",
    "x_1 = convToNpArray(x_1)\n",
    "x_test = convToNpArray(x_test)\n",
    "y_1 = convToNpArray(y_1)\n",
    "y_test = convToNpArray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.3, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Score:  0.9975559315660838\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'C':[1,10,10**2,10**4],\n",
    "                    'gamma':[0.1,0.3,0.5,0.7]}\n",
    "\n",
    "\n",
    "svc_model = SVC(kernel='rbf',class_weight='balanced')\n",
    "model = GridSearchCV(svc_model,tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.995124 \t TNR : 1.000000\n",
      "FPR : 0.000000 \t FNR: 0.004876\n"
     ]
    }
   ],
   "source": [
    "best_svc_model = model.best_estimator_\n",
    "best_svc_model.fit(x_1,y_1)\n",
    "pred = best_svc_model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=5.415547648717219, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.14175540339881265,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "Score:  1.0\n",
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :1.000000 \t TNR : 1.000000\n",
      "FPR : 0.000000 \t FNR: 0.000000\n"
     ]
    }
   ],
   "source": [
    "g_val=[]\n",
    "for i in range(10):\n",
    "    g_val.append(random.random())\n",
    "tuned_parameters = {'C':expon(scale=10),'gamma':g_val}\n",
    "\n",
    "\n",
    "model = RandomizedSearchCV(SVC(kernel='rbf',class_weight='balanced'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n",
    "best_svc_model = model.best_estimator_\n",
    "best_svc_model.fit(x_1,y_1)\n",
    "pred = best_svc_model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Summary of all Featurizations with Grid and Random Search CV.\n",
    "\n",
    "Observation: As Gamma val Increase the data is getting overfitted TPR is becoming 1 as Gamma val decreases its Underfitting FPR is tending towards 1.<br>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Featurization</th>\n",
    "        <th>CV</th>\n",
    "        <th>C</th>\n",
    "        <th>Gamma</th>\n",
    "        <th>F1 Score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>BOW</td>\n",
    "        <td>GridSearch</td>\n",
    "        <td>10</td>\n",
    "        <td>0.01</td>\n",
    "        <td>99.7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>BOW</td>\n",
    "        <td>RandomSearch</td>\n",
    "        <td>1.66</td>\n",
    "        <td>0.15</td>\n",
    "        <td>100</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Tf-Idf</td>\n",
    "        <td>GridSearch</td>\n",
    "        <td>1</td>\n",
    "        <td>0.3</td>\n",
    "        <td>99</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Tf-Idf</td>\n",
    "        <td>RandomSearch</td>\n",
    "        <td>5.4</td>\n",
    "        <td>0.14</td>\n",
    "        <td>100</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Avg W2V</td>\n",
    "        <td>GridSearch</td>\n",
    "        <td>100</td>\n",
    "        <td>0.1</td>\n",
    "        <td>93</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Avg W2V</td>\n",
    "        <td>RandomSearch</td>\n",
    "        <td>13.12</td>\n",
    "        <td>0.14</td>\n",
    "        <td>93.85</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "Note: Its Response Time is high when compared to other models.<br>\n",
    "###### Considered 10000 data points for train and 3000 data points as test\n",
    "###### Result may vary if we consider more data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
