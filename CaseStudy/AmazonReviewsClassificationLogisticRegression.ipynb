{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AmazonReviews Logistic Regression Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd #for data frames\n",
    "import numpy as np #numpy array operations\n",
    "import nltk #natural lang processing, for processing text\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #for plotting\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import average_precision_score,f1_score,precision_score,recall_score,auc,log_loss,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in=open(\"cleanedData.pickle\",\"rb\")\n",
    "final = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"BOW_tfidf_avgW2V_TfidfW2V.pickle\",\"rb\")\n",
    "count_vect = pickle.load(pickle_in) #BOW\n",
    "final_counts = pickle.load(pickle_in) #BOW\n",
    "\n",
    "tf_idf_vect = pickle.load(pickle_in) #TFIDF\n",
    "final_tf_idf = pickle.load(pickle_in) #TFIDF\n",
    "features = pickle.load(pickle_in) #TFIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364171"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = final['Score'].get_values()\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = lambda x: 1 if x=='positive'  else 0\n",
    "final_scores = []\n",
    "for i in range(0,364171):\n",
    "    final_scores.append(li(scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convToNpArray(arr):\n",
    "    if(type(arr) == list):\n",
    "        arr = np.array(arr)\n",
    "        return arr\n",
    "    else:\n",
    "        return arr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total data frame\n",
    "\n",
    "x = final_counts[0:10000]\n",
    "\n",
    "\n",
    "# this is only Score/rating  of data\n",
    "\n",
    "y = final_scores[0:10000]\n",
    "\n",
    "\n",
    "x_1, x_test, y_1, y_test = train_test_split(x,y, test_size=0.3, random_state=0)\n",
    "\n",
    "x_1 = convToNpArray(x_1)\n",
    "x_test = convToNpArray(x_test)\n",
    "y_1 = convToNpArray(y_1)\n",
    "y_test = convToNpArray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y_test,pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    tpr = tp/(fn+tp)\n",
    "    tnr = tn/(tn+fp)\n",
    "    fnr = fn/(fn+tp)\n",
    "    fpr = fp/(tn+fp)\n",
    "    \n",
    "    print(\"\\n######### Confusion Matrix #########\")\n",
    "    print(\"TPR :%f \\t TNR : %f\\nFPR : %f \\t FNR: %f\"%(tpr,tnr,fpr,fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Score:  0.9525976488433827\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C':[10**-2,10**0,10,10**2,10**4]}]\n",
    "\n",
    "lr_model = LogisticRegression(class_weight='balanced',penalty='l2');\n",
    "model = GridSearchCV(lr_model,tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.951876 \t TNR : 0.659280\n",
      "FPR : 0.340720 \t FNR: 0.048124\n"
     ]
    }
   ],
   "source": [
    "Lr_Model = LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "Lr_Model.fit(x_1,y_1)\n",
    "pred = Lr_Model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Score:  0.94859287054409\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C':[10**-2,10**0,10,10**2,10**4]}]\n",
    "\n",
    "model = GridSearchCV(LogisticRegression(class_weight='balanced',penalty='l1'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.956423 \t TNR : 0.567867\n",
      "FPR : 0.432133 \t FNR: 0.043577\n"
     ]
    }
   ],
   "source": [
    "Lr_Model = LogisticRegression(C=10000, class_weight='balanced', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "Lr_Model.fit(x_1,y_1)\n",
    "pred = Lr_Model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearch CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=31.679052419676523, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Score:  0.9509562582844158\n",
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.951497 \t TNR : 0.637119\n",
      "FPR : 0.362881 \t FNR: 0.048503\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "tuned_parameters = {'C':expon(scale=100)}\n",
    "\n",
    "model = RandomizedSearchCV(LogisticRegression(class_weight='balanced',penalty='l2'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n",
    "\n",
    "Lr_Model = model.best_estimator_\n",
    "Lr_Model.fit(x_1,y_1)\n",
    "pred = Lr_Model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=196.0818344361864, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Score:  0.9455987910842463\n",
      "\n",
      "######### Confusion Matrix #########\n",
      "TPR :0.948465 \t TNR : 0.581717\n",
      "FPR : 0.418283 \t FNR: 0.051535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tuned_parameters = {'C':expon(scale=100)}\n",
    "\n",
    "model = RandomizedSearchCV(LogisticRegression(class_weight='balanced',penalty='l1'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))\n",
    "\n",
    "Lr_Model = model.best_estimator_\n",
    "Lr_Model.fit(x_1,y_1)\n",
    "pred = Lr_Model.predict(x_test)\n",
    "confusionMatrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Performance with different lambdas/C with L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.0001 , No.of non zero vals:  0\n",
      "Score:  12.03333333333333\n",
      "Error:  87.96666666666667\n",
      "C =  0.001 , No.of non zero vals:  3\n",
      "Score:  87.96666666666667\n",
      "Error:  12.03333333333333\n",
      "C =  0.01 , No.of non zero vals:  13\n",
      "Score:  87.96666666666667\n",
      "Error:  12.03333333333333\n",
      "C =  0.1 , No.of non zero vals:  171\n",
      "Score:  89.53333333333333\n",
      "Error:  10.466666666666669\n",
      "C =  1 , No.of non zero vals:  842\n",
      "Score:  91.73333333333333\n",
      "Error:  8.266666666666666\n",
      "C =  10 , No.of non zero vals:  1240\n",
      "Score:  90.96666666666667\n",
      "Error:  9.033333333333339\n",
      "C =  100 , No.of non zero vals:  1358\n",
      "Score:  90.73333333333333\n",
      "Error:  9.266666666666667\n",
      "C =  1000 , No.of non zero vals:  2674\n",
      "Score:  91.60000000000001\n",
      "Error:  8.399999999999997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27f88e94fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "li_of_c_vals = [0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
    "li_of_errors=[]\n",
    "for i in li_of_c_vals:\n",
    "    model = LogisticRegression(C=i, penalty='l1')\n",
    "    model.fit(x_1,y_1)\n",
    "    w = model.coef_\n",
    "    err_val = 1-model.score(x_test,y_test);\n",
    "    print(\"C = \",i,\", No.of non zero vals: \",np.count_nonzero(w))\n",
    "    print(\"Score: \",(1-err_val)*100)\n",
    "    print(\"Error: \",(err_val)*100)\n",
    "    li_of_errors.append(err_val)\n",
    "\n",
    "plt.plot(li_of_c_vals,li_of_errors)\n",
    "plt.xlabel('C or 1/(lambda) value')\n",
    "plt.ylabel('Error Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:<br>\n",
    "As 'C' val decreases or Lambda val increases Error increases i.e model is underfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Collinearity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Noise to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.468860561221003e-05\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import normal\n",
    "ep=normal(loc=0.0,scale = 0.01)\n",
    "print(ep)\n",
    "\n",
    "noisyData = final_tf_idf[0:10000]\n",
    "# adding noise to non zero elements.\n",
    "noisyData[noisyData!=0]+=ep;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noisyData\n",
    "\n",
    "\n",
    "# this is only Score/rating  of data\n",
    "\n",
    "y = final_scores[0:10000]\n",
    "\n",
    "\n",
    "x_1, x_test, y_1, y_test = train_test_split(x,y, test_size=0.3, random_state=0)\n",
    "\n",
    "x_1 = convToNpArray(x_1)\n",
    "x_test = convToNpArray(x_test)\n",
    "y_1 = convToNpArray(y_1)\n",
    "y_test = convToNpArray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Score:  0.9577256784197894\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C':[10**-2,10**0,10,10**2,10**4]}]\n",
    "\n",
    "model = GridSearchCV(LogisticRegression(class_weight='balanced',penalty='l2'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "clf.fit(x_1,y_1)\n",
    "\n",
    "w_1 = clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data without Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = final_tf_idf[0:10000]\n",
    "\n",
    "\n",
    "# this is only Score/rating  of data\n",
    "\n",
    "y = final_scores[0:10000]\n",
    "\n",
    "\n",
    "x_1, x_test, y_1, y_test = train_test_split(x,y, test_size=0.3, random_state=0)\n",
    "\n",
    "x_1 = convToNpArray(x_1)\n",
    "x_test = convToNpArray(x_test)\n",
    "y_1 = convToNpArray(y_1)\n",
    "y_test = convToNpArray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "Score:  0.9577256784197894\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C':[10**-2,10**0,10,10**2,10**4]}]\n",
    "\n",
    "model = GridSearchCV(LogisticRegression(class_weight='balanced',penalty='l2'),tuned_parameters,\n",
    "                     scoring='f1',cv=5,n_jobs=4)\n",
    "\n",
    "model.fit(x_1,y_1)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(\"Score: \",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "clf.fit(x_1,y_1)\n",
    "\n",
    "w = clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difference between W's(without noise,with noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033024648368667066\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "#calculating euclidean distance between w and origin, w1 and origin\n",
    "d_w = numpy.linalg.norm(w[0]-np.zeros(len(w[0])))\n",
    "d_w1 = numpy.linalg.norm(w_1[0]-np.zeros(len(w_1[0])))\n",
    "\n",
    "# calculating difference percentage of w,w1 if its more than 30% then they are Multi Collinear\n",
    "# if its less than 30% not Multi Collinear then we can Use 'w' to get imp features,\n",
    "# if val of 'wj' is zero its considered as not imp feature or else it imp feature.\n",
    "\n",
    "diffPercentage=(abs(d_w-d_w1)/d_w)*100\n",
    "print(diffPercentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation:<br>\n",
    "As there is no much difference(its less than 30%) after adding noise i.e after perturbation they are not Multi Collinear so we can directly calculate Important Features from 'Wj' if 'Wj' is 0 its not important else its important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getImpFeatures(vectorizer,w_vec,top_n_features):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(w_vec[0], feature_names))\n",
    "    print(\"These are the top 20 important Features Which are most widely used in Positive and Negative Reviews:\")\n",
    "    pos_features = coefs_with_fns[len(feature_names)-top_n_features:len(feature_names)];\n",
    "    neg_features = coefs_with_fns[0:top_n_features];\n",
    "    print(\"\\n\")\n",
    "    print(\"Positive: \\t\\t\\t\\t Negative:\")\n",
    "    print(\"\\n\")\n",
    "    for i in range(20):\n",
    "        print(pos_features[i],\"\\t\\t\",neg_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the top 20 important Features Which are most widely used in Positive and Negative Reviews:\n",
      "\n",
      "\n",
      "Positive: \t\t\t\t Negative:\n",
      "\n",
      "\n",
      "(3.67269840222691, 'this is') \t\t (-11.022854495425578, 'not')\n",
      "(3.830396378404382, 'not too') \t\t (-5.919702871446887, 'bad')\n",
      "(3.8471012895105616, 'is the') \t\t (-5.203579659848787, 'was')\n",
      "(3.8937270060700473, 've') \t\t (-4.82529152939797, 'horrible')\n",
      "(3.906414952561781, 'well') \t\t (-4.7611614606687755, 'bland')\n",
      "(3.9764711662140724, 'wonderful') \t\t (-4.633196132031222, 'not worth')\n",
      "(3.9996887872215345, 'my') \t\t (-4.536424119124524, 'awful')\n",
      "(4.098975896733789, 'you') \t\t (-4.454289620730527, 'worst')\n",
      "(4.183771427232313, 'are') \t\t (-4.453348340689143, 'maybe')\n",
      "(4.2302564482631775, 'perfect') \t\t (-4.265050192227308, 'at all')\n",
      "(4.230877349078375, 'and') \t\t (-4.19376677640029, 'return')\n",
      "(4.274160608860285, 'use') \t\t (-4.1467478388618195, 'were')\n",
      "(4.579999278463121, 'good') \t\t (-4.096109095784286, 'instead')\n",
      "(4.612639553658168, 'excellent') \t\t (-4.079439265526672, 'ok')\n",
      "(4.671047024612496, 'love') \t\t (-4.0767977600891, 'the worst')\n",
      "(4.6714602021905725, 'nice') \t\t (-4.057347473359296, 'disgusting')\n",
      "(5.605323042033229, 'the best') \t\t (-4.030841934475372, 'terrible')\n",
      "(5.680373400135534, 'best') \t\t (-3.8605807716607763, 'did')\n",
      "(5.720677627127294, 'delicious') \t\t (-3.828510245689711, 'money')\n",
      "(10.6774382514121, 'great') \t\t (-3.808510323002438, 'away')\n"
     ]
    }
   ],
   "source": [
    "getImpFeatures(tf_idf_vect,w,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:<br>\n",
    "Performed Logistic Regression on Amazon Food Reviews, Used GridSearchCv and RandomSearchCv Observed that RandomSearchCV was fast, Used 2 types of Regularizations L2 and L1, Performed Multi Coliinearity Check and Observed that there is no much difference before and after adding Noise to the data so it can be said that Features are not multi collinear i.e Independent, so used 'W' to get the top 20 important features.<br>\n",
    "\n",
    "The Positive and Negative Features which we obtained are Perfect when compared to other technique like classifier.coef_ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Regularization</th>\n",
    "        <th>CV</th>\n",
    "        <th>Best HyperParameter(C)</th>\n",
    "        <th>Accuracy</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L2</td>\n",
    "        <td>GridSearch CV</td>\n",
    "        <td>10</td>\n",
    "        <td>95.2%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L1</td>\n",
    "        <td>GridSearchCV</td>\n",
    "        <td>1000</td>\n",
    "        <td>95.8%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L2</td>\n",
    "        <td>RandomSearch CV</td>\n",
    "        <td>31.67</td>\n",
    "        <td>95.09%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L1</td>\n",
    "        <td>RandomSearch CV</td>\n",
    "        <td>196.08</td>\n",
    "        <td>94.5%</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
